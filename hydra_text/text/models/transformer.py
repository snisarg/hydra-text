# Generated by configen, do not edit.
# See https://github.com/facebookresearch/hydra/tree/master/tools/configen
# fmt: off
# isort:skip_file
# flake8: noqa

from dataclasses import dataclass, field
from typing import Optional


@dataclass
class RobertaModelConf:
    _target_: str = "text.models.transformer.RobertaModel"
    model_path: Optional[str] = None
    vocab_size: int = 50265
    embedding_dim: int = 768
    num_attention_heads: int = 12
    num_encoder_layers: int = 12
    output_dropout: float = 0.4
    dense_dim: int = 0
    out_dim: int = 2
    bias: bool = True
